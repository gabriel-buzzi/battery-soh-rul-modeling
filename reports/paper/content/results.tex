\section{Results}

\subsection{Optimization Results}

The \cref{tab:soh_optim,tab:rul_optim} below show the results of the optimization process for both \acf{soh} and \acf{rul}, respectively. It can be seen that the models produced good values of validation \acf{rmse}, which is the average of the \ac{rmse} on each fold of cross validation, while maintaining low relative gaps which is a good indicative of non-overfitting models. For \ac{rul} models, authough it was harder to keep the relative gap values low, which indicates models for that target with the features extracted on this work are more prone to overfitt the training data.

\inserttable{soh_optim}
\inserttable{rul_optim}

The \cref{tab:soh_hyperparams,tab:rul_hyperparams} show the optimimal values of the hyperparams for \ac{soh} and \ac{rul}, respectively. 

\inserttable{soh_hyperparams}
\inserttable{rul_hyperparams}

\subsection{Test Results}

The results of each model type using the optimzal hyperparam set are shown on \cref{tab:soh_metrics,tab:rul_metrics} for \ac{soh} and \ac{rul}, respectively. The performance drop between using 16 and 4 features were relatively low indicating models with only the most important features identifies by the Tree-based ensamble recribed on \cref{sec:feature_extraction} is feasible.

The overall performance of all models is satisfatory with \ac{rmse} values below 0.80\% for \ac{soh} using a LGBMRegressor for 75\% of the test cells and below 59.91 for \ac{rul} using an ExtraTreesRegressor for 75\% of the test cells. \ac{r2} values for 75\% of the test cells were above 0.97 and 0.96 for \ac{soh} and \ac{rul}, respectively. Indicating high accordance between the models estimations and references values.

\inserttable{soh_metrics}
\inserttable{rul_metrics}

\cref{fig:best_16_soh_model,fig:best_16_rul_model,fig:best_4_soh_model,fig:best_4_rul_model} below show in detail the scatter plots of all reference vs. estimated values of all test cells for the best model in each case: \ac{soh} and \ac{rul} and unsing all 16 features and only 4 features. It can be confirmed that the model works realy well for most data while some points are more distant from the indeal fit line. For \ac{soh} models under and over estimate values while for \ac{rul} models tend to under estimate the values. For the \ac{rul} models with 16 and 4 features it can be noticed that a similar set of points diverge from the ideal regression line, we identified that this points corresponde to the same cell of the test set. From the plot it can be seen that this cells is the only with almost 2000 cycles cyclelife, this divergence of the model might be happening because data with \ac{rul} values that high are more scarce on the training set as well due to the fact fill cells cycle that long on the dataset used.

\insertfigure{results/best_16_soh_model}
\insertfigure{results/best_4_soh_model}
\insertfigure{results/best_16_rul_model}
\insertfigure{results/best_4_rul_model}

\section{Results and Discussion}
\subsection{Hyperparameter Optimization Performance}
The hyperparameter optimization process successfully identified optimal configurations for all machine learning models across both \ac{soh} and \ac{rul} prediction tasks. \cref{tab:soh_optim,tab:rul_optim} present the cross-validation performance metrics obtained during the optimization phase, revealing distinct patterns in model behavior and generalization capabilities.

For \ac{soh} prediction (\cref{tab:soh_optim}), the LGBMRegressor demonstrated superior performance with the lowest validation \ac{rmse} of 0.94\% when utilizing all 16 features, while maintaining a moderate relative gap of 0.44. This indicates a balanced trade-off between predictive accuracy and overfitting resistance. The ExtraTreesRegressor achieved comparable performance with a validation \ac{rmse} of 1.07\% and notably lower relative gap of 0.27, suggesting better generalization properties. The TweedieRegressor, while exhibiting excellent generalization characteristics ($relative gaps \leq 0.06$), showed substantially higher validation errors, indicating insufficient model complexity for capturing the underlying \ac{soh} patterns.

\ac{rul} prediction (\cref{tab:rul_optim}) proved more challenging, with all models exhibiting higher relative gaps compared to \ac{soh} estimation, suggesting increased susceptibility to overfitting. The ExtraTreesRegressor achieved the best validation performance with an \ac{rmse} of 103.64 cycles using 16 features, though with a concerning relative gap of 0.70. The LGBMRegressor, despite lower training error (18.51 cycles), showed an even larger relative gap of 0.83, indicating significant overfitting tendencies. The TweedieRegressor again demonstrated perfect generalization ($relative gap \approx 0.00$) but at the cost of substantially higher prediction errors.

\subsection{Impact of Feature Reduction}
The transition from 16 to 4 features resulted in predictable but manageable performance degradation across all models. For \ac{soh} prediction, validation \ac{rmse} increased by 20--30\% for tree-based methods (LGBMRegressor: $0.94\% \rightarrow 1.22\%$, ExtraTreesRegressor: $1.07\% \rightarrow
1.40\%$), while simultaneously reducing overfitting tendencies as evidenced by decreased relative gaps. This trade-off suggests that the four most important features capture the majority of \ac{soh}-relevant information, with additional features contributing primarily to model complexity rather than fundamental predictive power.

The feature reduction impact on \ac{rul} prediction was less pronounced, with validation \ac{rmse} changes typically within 10\% (ExtraTreesRegressor: $103.64 \rightarrow 110.00 cycles$). Notably, the reduced feature set generally improved generalization capabilities, with several models showing decreased relative gaps. This pattern indicates that \ac{rul} prediction may be more robust to feature dimensionality reduction, possibly due to the inherent noise in cycle-life estimation making additional features less beneficial.

\subsection{Optimal Hyperparameter Analysis}
The optimal hyperparameters (\cref{tab:soh_hyperparams,tab:rul_hyperparams}) reveal consistent patterns that provide insights into the underlying data characteristics and model requirements. For tree-based methods, the optimal configurations favored relatively shallow trees ($max\_depth \leq 10$) and small leaf sizes ($min\_samples\_leaf \leq 4$), suggesting that the battery aging patterns can be captured without excessive model complexity. The LGBMRegressor consistently selected low learning rates (0.007--0.11) paired with moderate numbers of estimators (400--661), indicating a preference for gradual learning to avoid overfitting.

Interestingly, the KNeighborsRegressor optimal configurations showed preference for relatively large neighborhood sizes (n\_neighbors = 21--35) and uniform weighting, suggesting that local averaging over substantial regions of the feature space is beneficial for battery prognostics. The consistent selection of Manhattan distance (p=1p=1
p=1) over Euclidean distance (p=2p=2
p=2) for most configurations may indicate that the standardized features exhibit more meaningful relationships under L1 norm.

\subsection{Model-Specific Performance Characteristics}

The superior performance of tree-based ensemble methods (LGBMRegressor and ExtraTreesRegressor) aligns with their inherent ability to capture non-linear relationships and feature interactions without explicit modeling. Battery aging involves complex, non-linear degradation mechanisms that these methods can naturally accommodate. The gradient boosting approach of LGBMRegressor appears particularly well-suited for \ac{soh} estimation, where sequential refinement of predictions can effectively model the gradual capacity fade patterns.
The consistently poor performance of TweedieRegressor, despite its excellent generalization properties, suggests that linear models---even with flexible error distributions---are insufficient for capturing the complexity of battery degradation patterns encoded in the extracted features. This finding reinforces the necessity of non-linear modeling approaches for battery prognostics applications.

\subsection{Test Set Performance and Model Validation}

The test set results (\cref{tab:soh_metrics,tab:rul_metrics}) demonstrate that the optimized models successfully generalize to unseen cells, with performance metrics closely matching the cross-validation estimates. For \ac{soh} prediction, the LGBMRegressor achieved an \ac{rmse} below 0.80\% for 75\% of test cells, with \acf{r2} values above 0.97, indicating high accordance between model estimations and reference values. Similarly, for \ac{rul} prediction, the ExtraTreesRegressor maintained \ac{rmse} values below 59.91 cycles for 75\% of test cells, with \ac{r2} values above 0.96.
The scatter plots (\cref{fig:best_16_soh_model,fig:best_16_rul_model,fig:best_4_soh_model,fig:best_4_rul_model}) provide detailed visualization of model performance across all test samples. For \ac{soh} models, the predictions show balanced distribution around the ideal fit line, with both under- and over-estimation patterns. In contrast, \ac{rul} models exhibit a tendency toward under-estimation, particularly evident in the high-cycle region where one test cell with approximately 2000 cycles consistently deviates from the ideal regression line. This divergence likely stems from the scarcity of such long-lived cells in the training dataset, highlighting a limitation in model generalization to extreme cycle-life scenarios.

\subsection{Practical Implications and Deployment Considerations}

From a practical battery management perspective, the results demonstrate that effective \ac{soh} and \ac{rul} estimation can be achieved using a minimal feature set derived from single charge-discharge cycles sampled at 1~Hz or higher. The 4-feature models, while showing modest performance reduction, offer significant computational advantages for embedded applications where processing power and memory are constrained.

However, a critical limitation for real-world deployment concerns data availability. The feature extraction methodology requires complete constant current constant voltage (CCCV) charge-discharge cycle data, which may not be readily available during normal battery operation in applications such as electric vehicles or grid energy storage systems. Such complete cycling data would typically only be obtainable during dedicated diagnostic procedures with the load disconnected from the battery, limiting the frequency of prognostic updates and potentially compromising the timeliness of health assessments. This constraint necessitates careful consideration of diagnostic scheduling and may require development of alternative feature extraction methods that can operate on partial cycle data or operational load profiles.

Despite this limitation, the observed performance characteristics suggest different deployment strategies for \ac{soh} and \ac{rul} estimation. \ac{soh} models demonstrate robust performance across the full range of battery conditions, making them suitable for periodic diagnostic monitoring applications. \ac{rul} models, while showing excellent performance for typical battery lifespans, may require additional training data or specialized handling for batteries exhibiting exceptional longevity, and their deployment would be similarly constrained by the need for complete cycle data.

\subsection{Limitations and Future Research Directions}

Several limitations must be acknowledged in the current optimization approach. The use of a 10\% subset (\cref{fig:subset_distributions}) for hyperparameter optimization, while computationally efficient, may not fully capture the complete data distribution complexity. Additionally, the focus on full-life training data, while comprehensive for model evaluation, may not reflect real-world scenarios where models must perform early-life predictions with limited degradation history.

A fundamental limitation lies in the requirement for complete CCCV cycle data for feature extraction. This dependency significantly restricts the practical applicability of the developed models, as such data is typically unavailable during normal battery operation and can only be obtained during scheduled diagnostic procedures. Future research should prioritize the development of feature extraction methods that can operate on partial cycle data, operational load profiles, or other readily available signals to enable continuous prognostic monitoring without service interruption.

The identified overfitting tendencies, particularly for \ac{rul} prediction, highlight the need for regularization strategies beyond hyperparameter optimization. Future work should investigate ensemble approaches that combine multiple models or incorporate physics-informed constraints to improve generalization while maintaining predictive accuracy. The development of hybrid models that combine the generalization properties of simpler methods with the predictive power of complex ensemble approaches could address the observed overfitting issues.

The consistent challenges observed in \ac{rul} prediction across all models indicate a need for alternative problem formulations, such as classification-based approaches that predict remaining life ranges rather than precise cycle counts, or multi-task learning frameworks that jointly optimize \ac{soh} and \ac{rul} estimation to leverage their inherent relationships. Additionally, investigating domain-specific regularization techniques that incorporate known battery aging physics could improve model robustness and reduce the sensitivity to training data distribution variations.
